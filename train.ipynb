{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%pip install datasets==2.0.0\n",
        "import os\n",
        "import re\n",
        "import json\n",
        "import requests\n",
        "from pathlib import Path\n",
        "from urllib.parse import urlparse"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Requirement already satisfied: datasets==2.0.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (2.0.0)\nRequirement already satisfied: requests>=2.19.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from datasets==2.0.0) (2.27.1)\nRequirement already satisfied: fsspec[http]>=2021.05.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from datasets==2.0.0) (2022.5.0)\nRequirement already satisfied: numpy>=1.17 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from datasets==2.0.0) (1.22.3)\nRequirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from datasets==2.0.0) (0.7.0)\nRequirement already satisfied: packaging in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from datasets==2.0.0) (21.3)\nRequirement already satisfied: dill in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from datasets==2.0.0) (0.3.4)\nRequirement already satisfied: xxhash in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from datasets==2.0.0) (3.0.0)\nRequirement already satisfied: pyarrow>=5.0.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from datasets==2.0.0) (8.0.0)\nRequirement already satisfied: pandas in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from datasets==2.0.0) (1.4.2)\nRequirement already satisfied: multiprocess in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from datasets==2.0.0) (0.70.12.2)\nRequirement already satisfied: tqdm>=4.62.1 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from datasets==2.0.0) (4.64.0)\nRequirement already satisfied: responses<0.19 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from datasets==2.0.0) (0.18.0)\nRequirement already satisfied: aiohttp in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from datasets==2.0.0) (3.8.1)\nRequirement already satisfied: filelock in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets==2.0.0) (3.7.1)\nRequirement already satisfied: pyyaml>=5.1 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets==2.0.0) (6.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets==2.0.0) (4.2.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from packaging->datasets==2.0.0) (3.0.8)\nRequirement already satisfied: certifi>=2017.4.17 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from requests>=2.19.0->datasets==2.0.0) (2021.10.8)\nRequirement already satisfied: charset-normalizer~=2.0.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from requests>=2.19.0->datasets==2.0.0) (2.0.12)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from requests>=2.19.0->datasets==2.0.0) (1.26.9)\nRequirement already satisfied: idna<4,>=2.5 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from requests>=2.19.0->datasets==2.0.0) (3.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from aiohttp->datasets==2.0.0) (1.3.0)\nRequirement already satisfied: yarl<2.0,>=1.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from aiohttp->datasets==2.0.0) (1.7.2)\nRequirement already satisfied: aiosignal>=1.1.2 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from aiohttp->datasets==2.0.0) (1.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from aiohttp->datasets==2.0.0) (6.0.2)\nRequirement already satisfied: attrs>=17.3.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from aiohttp->datasets==2.0.0) (21.4.0)\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from aiohttp->datasets==2.0.0) (4.0.2)\nRequirement already satisfied: python-dateutil>=2.8.1 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from pandas->datasets==2.0.0) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from pandas->datasets==2.0.0) (2022.1)\nRequirement already satisfied: six>=1.5 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from python-dateutil>=2.8.1->pandas->datasets==2.0.0) (1.16.0)\nNote: you may need to restart the kernel to use updated packages.\n"
        }
      ],
      "execution_count": 3,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"./data/homer/homer.json\", \"r\") as f:\n",
        "    sources = json.load(f)\n",
        "sources"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 4,
          "data": {
            "text/plain": "[{'title': 'The Iliad, by Homer',\n  'source': '6130-0.txt',\n  'start': 4133,\n  'end': 23285,\n  'ignore': {'startswith': ['[Illustration:', 'BOOK', 'ARGUMENT'],\n   'isupper': True},\n  'replace': {'\\\\[\\\\d+\\\\]': ''}},\n {'title': 'The Odyssey, by Homer',\n  'source': 'pg1727.txt',\n  'start': 740,\n  'end': 10833,\n  'ignore': {'startswith': 'BOOK', 'isupper': True}}]"
          },
          "metadata": {}
        }
      ],
      "execution_count": 4,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "def check(s, ignore):\n",
        "    r = []\n",
        "    for a in ignore.keys():\n",
        "        if not hasattr(str, a):\n",
        "            continue\n",
        "\n",
        "        fn = getattr(str, a)\n",
        "        if type(ignore[a]) == str:\n",
        "            r += [fn(s, ignore[a])]\n",
        "\n",
        "        elif type(ignore[a]) == list:\n",
        "            r += [fn(s, i) for i in ignore[a]]\n",
        "\n",
        "        elif type(ignore[a]) == bool and ignore[a]:\n",
        "            r += [fn(s)]\n",
        "\n",
        "    return any(r)"
      ],
      "outputs": [],
      "execution_count": 5,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "def substitute(s, replace):\n",
        "    for a in replace.keys():\n",
        "        s = re.sub(a, replace[a], s)\n",
        "    return s"
      ],
      "outputs": [],
      "execution_count": 6,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "def load(\n",
        "    title=\"\",\n",
        "    source=\"\",\n",
        "    start=0,\n",
        "    end=100,\n",
        "    ignore={},\n",
        "    replace={},\n",
        "    base_path: Path = Path(\".\"),\n",
        "):\n",
        "    print(f\"processing '{title}'\")\n",
        "\n",
        "    # load text\n",
        "    file = base_path.resolve().absolute() / source\n",
        "    print(f\"Using {file}\", end=\"... \")\n",
        "    with open(str(file), \"r\", encoding=\"utf-8\") as f:\n",
        "        text = f.read()\n",
        "\n",
        "    lines = text.encode(\"ascii\", errors=\"ignore\").decode(\"ascii\").split(\"\\n\")[start:end]\n",
        "\n",
        "    # cleaned sentences\n",
        "    sentences = [\n",
        "        f\"{s.strip()}.\"\n",
        "        for s in \" \".join(\n",
        "            [\n",
        "                substitute(item, replace).strip()\n",
        "                for item in lines\n",
        "                if len(item) > 0 and not check(item, ignore)\n",
        "            ]\n",
        "        ).split(\".\")\n",
        "    ]\n",
        "    print(\"done!\")\n",
        "    return sentences\n"
      ],
      "outputs": [],
      "execution_count": 7,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"./data/homer/homer.raw.txt\", \"w\") as f:\n",
        "    for source_id in [0, 1]:\n",
        "        text =  load(**sources[source_id], base_path=Path('./data/homer'))\n",
        "        for line in text:\n",
        "            print(line, file=f)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "processing 'The Iliad, by Homer'\nUsing /mnt/batch/tasks/shared/LS_root/mounts/clusters/gpuciaz/code/Users/alzeltov/locutus/data/homer/6130-0.txt... done!\nprocessing 'The Odyssey, by Homer'\nUsing /mnt/batch/tasks/shared/LS_root/mounts/clusters/gpuciaz/code/Users/alzeltov/locutus/data/homer/pg1727.txt... done!\n"
        }
      ],
      "execution_count": 8,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fine-tuning model \n",
        "\n",
        "Based on https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_clm.py"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "root_dir = Path(\"./model\").resolve()\n",
        "config_path = root_dir / \"config\"\n",
        "model_path = root_dir / \"weights\"\n",
        "tokenizer_path = root_dir / \"tokenizer\"\n",
        "cache_dir = root_dir / \".cache\"\n",
        "output_dir = root_dir / \".outputs\"\n",
        "data_path = Path(\"./data/homer\").resolve() / \"homer.raw.txt\""
      ],
      "outputs": [],
      "execution_count": 9,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# load dataset and process it\n",
        "from datasets import load_dataset\n",
        "\n",
        "data_files = {}\n",
        "dataset_args = {}\n",
        "data_files[\"train\"] = str(data_path)\n",
        "extension = \"text\"\n",
        "dataset_args[\"keep_linebreaks\"] = True\n",
        "raw_datasets = load_dataset(extension, data_files=data_files, cache_dir=cache_dir, **dataset_args)\n",
        "\n",
        "# train:val split = 80:20\n",
        "validation_split_percentage = 20\n",
        "raw_datasets[\"validation\"] = load_dataset(\n",
        "    extension,\n",
        "    data_files=data_files,\n",
        "    split=f\"train[:{validation_split_percentage}%]\",\n",
        "    cache_dir=cache_dir,\n",
        "    **dataset_args,\n",
        ")\n",
        "raw_datasets[\"train\"] = load_dataset(\n",
        "    extension,\n",
        "    data_files=data_files,\n",
        "    split=f\"train[{validation_split_percentage}%:]\",\n",
        "    cache_dir=cache_dir,\n",
        "    **dataset_args,\n",
        ")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n  from .autonotebook import tqdm as notebook_tqdm\n2022/06/07 14:59:59 INFO mlflow.tracking.fluent: Autologging successfully enabled for tensorflow.\nUsing custom data configuration default-37e9673ffbb3a58d\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Downloading and preparing dataset text/default to /mnt/batch/tasks/shared/LS_root/mounts/clusters/gpuciaz/code/Users/alzeltov/locutus/model/.cache/text/default-37e9673ffbb3a58d/0.0.0/4b86d314f7236db91f0a0f5cda32d4375445e64c5eda2692655dd99c2dac68e8...\nDataset text downloaded and prepared to /mnt/batch/tasks/shared/LS_root/mounts/clusters/gpuciaz/code/Users/alzeltov/locutus/model/.cache/text/default-37e9673ffbb3a58d/0.0.0/4b86d314f7236db91f0a0f5cda32d4375445e64c5eda2692655dd99c2dac68e8. Subsequent calls will reuse this data.\n"
        }
      ],
      "execution_count": 10,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "# Load pretrained model and tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(tokenizer_path, use_fast_tokenizer=True, cache_dir=cache_dir)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_path, config=config_path, cache_dir=cache_dir)\n",
        "model.resize_token_embeddings(len(tokenizer))"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 11,
          "data": {
            "text/plain": "Embedding(50257, 768)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 11,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TextGenerationPipeline\n",
        "\n",
        "# generate text from prefix before fine-tuning\n",
        "device = -1 if model.device.type == \"cpu\" else model.device.index\n",
        "text_generator = TextGenerationPipeline(model=model, tokenizer=tokenizer, device=device)\n",
        "print(text_generator(\"The war in\")[0][\"generated_text\"])\n",
        "print(text_generator(\"The market in America\")[0][\"generated_text\"])"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "2022/06/07 15:00:18 INFO mlflow.tracking.fluent: Autologging successfully enabled for sklearn.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
        }
      ],
      "execution_count": 12,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocessing the datasets.\n",
        "# First we tokenize all the texts.\n",
        "column_names = raw_datasets[\"train\"].column_names\n",
        "text_column_name = \"text\" if \"text\" in column_names else column_names[0]\n",
        "\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples[text_column_name])\n",
        "\n",
        "tokenized_datasets = raw_datasets.map(\n",
        "    tokenize_function,\n",
        "    batched=True,\n",
        "    remove_columns=column_names,\n",
        "    desc=\"Running tokenizer on dataset\",\n",
        ")\n",
        "\n",
        "#block_size = tokenizer.model_max_length\n",
        "block_size = 256"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "\rRunning tokenizer on dataset:   0%|          | 0/2 [00:00<?, ?ba/s]\rRunning tokenizer on dataset: 100%|██████████| 2/2 [00:00<00:00, 17.30ba/s]\rRunning tokenizer on dataset: 100%|██████████| 2/2 [00:00<00:00, 17.16ba/s]\n\rRunning tokenizer on dataset:   0%|          | 0/1 [00:00<?, ?ba/s]\rRunning tokenizer on dataset: 100%|██████████| 1/1 [00:00<00:00, 14.45ba/s]\n"
        }
      ],
      "execution_count": 13,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from itertools import chain\n",
        "\n",
        "# Main data processing function that will concatenate all texts from our dataset and generate chunks of block_size.\n",
        "def group_texts(examples):\n",
        "    # Concatenate all texts.\n",
        "    concatenated_examples = {k: list(chain(*examples[k])) for k in examples.keys()}\n",
        "    total_length = len(concatenated_examples[list(examples.keys())[0]])\n",
        "    # We drop the small remainder, we could add padding if the model supported it instead of this drop, you can\n",
        "    # customize this part to your needs.\n",
        "    if total_length >= block_size:\n",
        "        total_length = (total_length // block_size) * block_size\n",
        "    # Split by chunks of max_len.\n",
        "    result = {\n",
        "        k: [t[i : i + block_size] for i in range(0, total_length, block_size)]\n",
        "        for k, t in concatenated_examples.items()\n",
        "    }\n",
        "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
        "    return result\n",
        "\n",
        "lm_datasets = tokenized_datasets.map(\n",
        "    group_texts,\n",
        "    batched=True,\n",
        "    desc=f\"Grouping texts in chunks of {block_size}\",\n",
        ")\n",
        "\n",
        "train_dataset = lm_datasets[\"train\"]\n",
        "eval_dataset = lm_datasets[\"validation\"]"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "\rGrouping texts in chunks of 256:   0%|          | 0/2 [00:00<?, ?ba/s]\rGrouping texts in chunks of 256:  50%|█████     | 1/2 [00:00<00:00,  7.49ba/s]\rGrouping texts in chunks of 256: 100%|██████████| 2/2 [00:00<00:00, 13.16ba/s]\n\rGrouping texts in chunks of 256:   0%|          | 0/1 [00:00<?, ?ba/s]\rGrouping texts in chunks of 256: 100%|██████████| 1/1 [00:00<00:00,  7.25ba/s]\rGrouping texts in chunks of 256: 100%|██████████| 1/1 [00:00<00:00,  7.21ba/s]\n"
        }
      ],
      "execution_count": 14,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_logits_for_metrics(logits, labels):\n",
        "    if isinstance(logits, tuple):\n",
        "        # Depending on the model and config, logits may contain extra tensors,\n",
        "        # like past_key_values, but logits always come first\n",
        "        logits = logits[0]\n",
        "    return logits.argmax(dim=-1)\n",
        "\n",
        "from datasets import load_metric\n",
        "metric = load_metric(\"accuracy\")\n",
        "\n",
        "def compute_metrics(eval_preds):\n",
        "    preds, labels = eval_preds\n",
        "    # preds have the same shape as the labels, after the argmax(-1) has been calculated\n",
        "    # by preprocess_logits_for_metrics but we need to shift the labels\n",
        "    labels = labels[:, 1:].reshape(-1)\n",
        "    preds = preds[:, :-1].reshape(-1)\n",
        "    return metric.compute(predictions=preds, references=labels)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "\rDownloading builder script:   0%|          | 0.00/1.41k [00:00<?, ?B/s]\rDownloading builder script: 3.19kB [00:00, 2.35MB/s]                   \n"
        }
      ],
      "execution_count": 15,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments\n",
        "\n",
        "# initialize traing arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=str(output_dir), \n",
        "    do_train=True, \n",
        "    do_eval=True,\n",
        "    per_device_train_batch_size = 4,\n",
        "    per_device_eval_batch_size = 4,\n",
        "    eval_accumulation_steps = 1,\n",
        "    num_train_epochs = 20\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 16,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Trainer, default_data_collator, is_torch_tpu_available\n",
        "\n",
        "# Initialize our Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset if training_args.do_train else None,\n",
        "    eval_dataset=eval_dataset if training_args.do_eval else None,\n",
        "    tokenizer=tokenizer,\n",
        "    # Data collator will default to DataCollatorWithPadding, so we change it.\n",
        "    data_collator=default_data_collator,\n",
        "    compute_metrics=compute_metrics if training_args.do_eval and not is_torch_tpu_available() else None,\n",
        "    preprocess_logits_for_metrics=preprocess_logits_for_metrics\n",
        "    if training_args.do_eval and not is_torch_tpu_available()\n",
        "    else None,\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 17,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "last_checkpoint = None"
      ],
      "outputs": [],
      "execution_count": 18,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# train\n",
        "if training_args.do_train:\n",
        "    checkpoint = None\n",
        "    if training_args.resume_from_checkpoint is not None:\n",
        "        checkpoint = training_args.resume_from_checkpoint\n",
        "    elif last_checkpoint is not None:\n",
        "        checkpoint = last_checkpoint\n",
        "    train_result = trainer.train(resume_from_checkpoint=checkpoint)\n",
        "    trainer.save_model()  # Saves the tokenizer too for easy upload\n",
        "\n",
        "    metrics = train_result.metrics\n",
        "\n",
        "    max_train_samples = len(train_dataset)\n",
        "   \n",
        "    metrics[\"train_samples\"] = min(max_train_samples, len(train_dataset))\n",
        "\n",
        "    trainer.log_metrics(\"train\", metrics)\n",
        "    trainer.save_metrics(\"train\", metrics)\n",
        "    trainer.save_state()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n***** Running training *****\n  Num examples = 220\n  Num Epochs = 20\n  Instantaneous batch size per device = 4\n  Total train batch size (w. parallel, distributed & accumulation) = 4\n  Gradient Accumulation steps = 1\n  Total optimization steps = 1100\n"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "\n    <div>\n      \n      <progress value='1100' max='1100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1100/1100 16:01, Epoch 20/20]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>500</td>\n      <td>2.771700</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>1.898000</td>\n    </tr>\n  </tbody>\n</table><p>"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nAttempted to log scalar metric loss:\n2.7717\nAttempted to log scalar metric learning_rate:\n2.7272727272727273e-05\nAttempted to log scalar metric epoch:\n9.09\nAttempted to log scalar metric loss:\n1.898\nAttempted to log scalar metric learning_rate:\n4.5454545454545455e-06\nAttempted to log scalar metric epoch:\n18.18\n"
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Saving model checkpoint to /mnt/batch/tasks/shared/LS_root/mounts/clusters/gpuciaz/code/Users/alzeltov/locutus/model/.outputs/checkpoint-500\nConfiguration saved in /mnt/batch/tasks/shared/LS_root/mounts/clusters/gpuciaz/code/Users/alzeltov/locutus/model/.outputs/checkpoint-500/config.json\nModel weights saved in /mnt/batch/tasks/shared/LS_root/mounts/clusters/gpuciaz/code/Users/alzeltov/locutus/model/.outputs/checkpoint-500/pytorch_model.bin\ntokenizer config file saved in /mnt/batch/tasks/shared/LS_root/mounts/clusters/gpuciaz/code/Users/alzeltov/locutus/model/.outputs/checkpoint-500/tokenizer_config.json\nSpecial tokens file saved in /mnt/batch/tasks/shared/LS_root/mounts/clusters/gpuciaz/code/Users/alzeltov/locutus/model/.outputs/checkpoint-500/special_tokens_map.json\nSaving model checkpoint to /mnt/batch/tasks/shared/LS_root/mounts/clusters/gpuciaz/code/Users/alzeltov/locutus/model/.outputs/checkpoint-1000\nConfiguration saved in /mnt/batch/tasks/shared/LS_root/mounts/clusters/gpuciaz/code/Users/alzeltov/locutus/model/.outputs/checkpoint-1000/config.json\nModel weights saved in /mnt/batch/tasks/shared/LS_root/mounts/clusters/gpuciaz/code/Users/alzeltov/locutus/model/.outputs/checkpoint-1000/pytorch_model.bin\ntokenizer config file saved in /mnt/batch/tasks/shared/LS_root/mounts/clusters/gpuciaz/code/Users/alzeltov/locutus/model/.outputs/checkpoint-1000/tokenizer_config.json\nSpecial tokens file saved in /mnt/batch/tasks/shared/LS_root/mounts/clusters/gpuciaz/code/Users/alzeltov/locutus/model/.outputs/checkpoint-1000/special_tokens_map.json\n\n\nTraining completed. Do not forget to share your model on huggingface.co/models =)\n\n\nSaving model checkpoint to /mnt/batch/tasks/shared/LS_root/mounts/clusters/gpuciaz/code/Users/alzeltov/locutus/model/.outputs\nConfiguration saved in /mnt/batch/tasks/shared/LS_root/mounts/clusters/gpuciaz/code/Users/alzeltov/locutus/model/.outputs/config.json\nModel weights saved in /mnt/batch/tasks/shared/LS_root/mounts/clusters/gpuciaz/code/Users/alzeltov/locutus/model/.outputs/pytorch_model.bin\ntokenizer config file saved in /mnt/batch/tasks/shared/LS_root/mounts/clusters/gpuciaz/code/Users/alzeltov/locutus/model/.outputs/tokenizer_config.json\nSpecial tokens file saved in /mnt/batch/tasks/shared/LS_root/mounts/clusters/gpuciaz/code/Users/alzeltov/locutus/model/.outputs/special_tokens_map.json\n"
        }
      ],
      "execution_count": 19,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "# eval\n",
        "if training_args.do_eval:\n",
        "    metrics = trainer.evaluate()\n",
        "    max_eval_samples = len(eval_dataset)\n",
        "    metrics[\"eval_samples\"] = min(max_eval_samples, len(eval_dataset))\n",
        "    perplexity = math.exp(metrics[\"eval_loss\"])\n",
        "    metrics[\"perplexity\"] = perplexity\n",
        "\n",
        "metrics"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "***** Running Evaluation *****\n  Num examples = 56\n  Batch size = 4\n"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "\n    <div>\n      \n      <progress value='14' max='14' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [14/14 00:02]\n    </div>\n    "
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Attempted to log scalar metric eval_loss:\n3.7507991790771484\nAttempted to log scalar metric eval_accuracy:\n0.3490896358543417\nAttempted to log scalar metric eval_runtime:\n2.8389\nAttempted to log scalar metric eval_samples_per_second:\n19.726\nAttempted to log scalar metric eval_steps_per_second:\n4.932\nAttempted to log scalar metric epoch:\n20.0\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 20,
          "data": {
            "text/plain": "{'eval_loss': 3.7507991790771484,\n 'eval_accuracy': 0.3490896358543417,\n 'eval_runtime': 2.8389,\n 'eval_samples_per_second': 19.726,\n 'eval_steps_per_second': 4.932,\n 'epoch': 20.0,\n 'eval_samples': 56,\n 'perplexity': 42.555077541588325}"
          },
          "metadata": {}
        }
      ],
      "execution_count": 20,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TextGenerationPipeline\n",
        "\n",
        "# generate text from prefix after fine-tuning\n",
        "device = -1 if model.device.type == \"cpu\" else model.device.index\n",
        "text_generator = TextGenerationPipeline(model=model, tokenizer=tokenizer, device=device)\n",
        "\n",
        "x = text_generator(\"The war in\")\n",
        "y = text_generator(\"The market in America\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
        }
      ],
      "execution_count": 21,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "device"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 23,
          "data": {
            "text/plain": "0"
          },
          "metadata": {}
        }
      ],
      "execution_count": 23,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x, y"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 22,
          "data": {
            "text/plain": "([{'generated_text': 'The war in the Aeaean island raged on for two days and three nights, and on the'}],\n [{'generated_text': 'The market in America is so great that it breeds many vagabonds, and it breeds many drug'}])"
          },
          "metadata": {}
        }
      ],
      "execution_count": 22,
      "metadata": {}
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "dbaf699705a9d2c0424d3e39b0fb26cef1fc49f20dae9718b3681441105d6206"
    },
    "kernelspec": {
      "display_name": "Python 3.10.0 ('.venv': venv)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "orig_nbformat": 4,
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}